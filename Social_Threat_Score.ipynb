{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tweepy\n",
    "import time\n",
    "import csv\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as swords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import twint\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your API tokens from a file\n",
    "TWITTER = open(\"TwiTokens.bak\", \"r\").read().splitlines()\n",
    "auth = tweepy.OAuthHandler(TWITTER[6], TWITTER[7])\n",
    "auth.set_access_token(TWITTER[8], TWITTER[9])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-blackberry",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grab info of YOUR account. This is so you can analyze your own followers.\n",
    "user = api.get_user('YOUR_ACCOUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-reputation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"user: {user.screen_name}\")\n",
    "print(f\"user ID: {user.id}\")\n",
    "print(f\"Bio: {user.description}\")\n",
    "print(f\"Since: {user.created_at}\")\n",
    "print(f\"Total Tweets: {user.statuses_count}\")\n",
    "print(f\"Following: {user.friends_count}\")\n",
    "print(f\"Followers: {user.followers_count}\")\n",
    "print(f\"Verified?: {user.verified}\")\n",
    "print(f\"Last Tweet Date: {user.status.created_at}\")\n",
    "print(f\"Last Tweet Text: {user.status.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-negotiation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "followers = api.followers_ids('YOUR_ACCOUNT')\n",
    "print(followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = followers[:]\n",
    "print(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Following: {user.friends_count}\")\n",
    "print(f\"Followers: {user.followers_count}\")\n",
    "print(f\"Follow ratio: {user.friends_count / user.followers_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = followers[:] # make a copy of the list, for an original, and for one that decreases in size as it is analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-terrorist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('tweet_analysis.csv', 'a') as tweet_file:\n",
    "    for profile in profiles:\n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"Scraping {profile}\")\n",
    "                account = api.get_user(profile)\n",
    "                csv_string = f'{account.screen_name},{account.id},{account.created_at},{account.statuses_count},{account.friends_count},{account.followers_count},{account.verified},{account.status.created_at}\\n'\n",
    "                print(csv_string)\n",
    "                tweet_file.write(csv_string)\n",
    "                tweet_file.flush()\n",
    "                profiles.remove(profile)\n",
    "                time.sleep(15)\n",
    "            except AttributeError as a:\n",
    "                print(a)\n",
    "                csv_string = f'{account.screen_name},{account.id},{account.created_at},{account.statuses_count},{account.friends_count},{account.followers_count},{account.verified},NULL\\n'\n",
    "                print(csv_string)\n",
    "                tweet_file.write(csv_string)\n",
    "                tweet_file.flush()\n",
    "                profiles.remove(profile)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Probably a connection error. Retrying in like....15 seconds\")\n",
    "                time.sleep(15)\n",
    "                continue\n",
    "            break\n",
    "tweet_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profiles)\n",
    "print(\"---\")\n",
    "print(followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(profiles))\n",
    "print(len(followers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-florida",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for profile in profiles:\n",
    "    while True:\n",
    "        try:\n",
    "            acct = api.get_user(profile)\n",
    "            print(f\"{acct.screen_name}: {acct.protected}\")\n",
    "            time.sleep(5)\n",
    "        except AttributeError:\n",
    "            print(f\"Manually check if {acct.screen_name} is protected\")\n",
    "            pass\n",
    "        except:\n",
    "            print(\"Connection issue me thinks...waiting\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-colors",
   "metadata": {},
   "source": [
    "raw_df = pd.read_csv('2021-03-01_tweet_analysis.csv')\n",
    "raw_df.loc[raw_df['followng'] <= 2]\n",
    "#print(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('2021-03-01_tweet_analysis.csv') \n",
    "raw_df.loc[raw_df['followers'] <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_df = raw_df.loc[raw_df['followers'] > 0]\n",
    "print(active_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Means: Following {active_users_df['following'].mean()}, Followers {active_users_df['followers'].mean()} Tweets {active_users_df['tweet_count'].mean()}\")\n",
    "print(f\"Medians: Following {active_users_df['following'].median()}, Followers {active_users_df['followers'].median()} Tweets {active_users_df['tweet_count'].median()}\")\n",
    "print(f\"Modes: Following {active_users_df['following'].mode()}, Followers {active_users_df['followers'].mode()} Tweets {active_users_df['tweet_count'].mode()}\")\n",
    "print(f\"Mins: Following {active_users_df['following'].min()}, Followers {active_users_df['followers'].min()} Tweets {active_users_df['tweet_count'].min()}\")\n",
    "print(f\"Maxes: Following {active_users_df['following'].max()}, Followers {active_users_df['followers'].max()} Tweets {active_users_df['tweet_count'].max()}\")\n",
    "print(f\"S. Deviations: Following {active_users_df['following'].std()}, Followers {active_users_df['followers'].std()} Tweets {active_users_df['tweet_count'].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_df['follow_ratio'] = active_users_df[\"following\"]/active_users_df[\"followers\"]\n",
    "print(active_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-intervention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_users_df[\"follow_ratio\"] = active_users_df[\"following\"]/active_users_df[\"followers\"]\n",
    "active_users_df[\"user\", \"follow_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_ratio = active_users_df.sort_values('follow_ratio').head(20)\n",
    "top_20_follower_count = active_users_df.sort_values('followers', ascending = False).head(20)\n",
    "top_20_tweet_count = active_users_df.sort_values('tweet_count', ascending = False).head(20)\n",
    "influencers = []\n",
    "for user in top_20_ratio['user']:\n",
    "    influencers.append(user)\n",
    "for user in top_20_follower_count['user']:\n",
    "    influencers.append(user)\n",
    "for user in top_20_tweet_count['user']:\n",
    "    influencers.append(user)\n",
    "print(influencers)\n",
    "with open('influencers.txt', 'w+') as i_file:\n",
    "    for influencer in influencers:\n",
    "        i_file.write(f'{influencer}\\n')\n",
    "i_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_influencers = {}\n",
    "for influencer in influencers:\n",
    "    if influencer not in unique_influencers:\n",
    "        unique_influencers[influencer] = 1\n",
    "    else:\n",
    "        unique_influencers[influencer] += 1\n",
    "print(unique_influencers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-midnight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for influencer in unique_influencers:\n",
    "    while True:\n",
    "        try:\n",
    "            with open(f'{influencer}.txt', 'w+') as i_file:\n",
    "                for tweet in tweepy.Cursor(api.user_timeline, id=influencer).items():\n",
    "                    i_file.write(f'{tweet.text}\\n')\n",
    "                    i_file.flush()\n",
    "            i_file.close()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)\n",
    "            #continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_df = active_users_df.loc[active_users_df['tweet_count'] > 0]\n",
    "print(active_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "verified = len(active_users_df.loc[active_users_df['verified'] == True])\n",
    "unverified = len(active_users_df.loc[active_users_df['verified'] == False])\n",
    "print(f\"Verified: {verified}\")\n",
    "print(f\"Unverified: {unverified}\")\n",
    "print(f\"Verified Percentage: {verified/len(api.followers_ids(user))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users_df.loc[active_users_df['follow_ratio'] <= 1.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "#active_users_df.loc[active_users_df['following'] <= 20]\n",
    "active_users_df[active_users_df['last_tweet_date'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(active_users_df['followers'], active_users_df['tweet_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(active_users_df['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-classics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(unique_influencers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-prison",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "for influencer in unique_influencers:\n",
    "    word_count = 0\n",
    "    rt_list = []\n",
    "    word_dict = {}\n",
    "    hashtags = {}\n",
    "    links = []\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    with open(f'{influencer}.txt', 'r') as i_file:\n",
    "        tweets = i_file.readlines()\n",
    "        \n",
    "        for tweet in tweets:\n",
    "            tweet = tweet.lower()\n",
    "            curr_string = tweet.split()\n",
    "            for word in curr_string:\n",
    "                if 'http:' in word or 'https:' in word:\n",
    "                    links.append(word)\n",
    "\n",
    "            if tweet.startswith('rt'):\n",
    "                rt_list.append(tweet)\n",
    "    \n",
    "            #curr_string = tweet.split()\n",
    "            for word in curr_string:\n",
    "                if 'http:' in word or 'https:' in word:\n",
    "                    links.append(word)\n",
    "                    pass\n",
    "                if word in stopwords:\n",
    "                    pass\n",
    "                if word.startswith('#'):\n",
    "                    word = word.translate(table)\n",
    "                    if word not in hashtags:\n",
    "                        hashtags[word] = 1\n",
    "                    else:\n",
    "                        hashtags[word] += 1\n",
    "                    \n",
    "                word = word.translate(table)\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = 1\n",
    "                else:\n",
    "                    word_dict[word] += 1\n",
    "        full_text = \" \".join(word for word in word_dict)\n",
    "        try:\n",
    "            word_cloud = WordCloud(stopwords=stopwords).generate(full_text)\n",
    "            plt.imshow(word_cloud, interpolation='bilinear')\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "        except:\n",
    "            print(\"No words for the WordCloud apparently\")\n",
    "        i_file.close()\n",
    "        for word in word_dict.copy():\n",
    "            if word in swords.words('english'):\n",
    "                del word_dict[word]\n",
    "        sort_words = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(\"---Top words---\")\n",
    "        for i in sort_words[:20]:\n",
    "            print(i[0], i[1])\n",
    "        sorted_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(\"---Top hashtags---\")\n",
    "        for i in sorted_hashtags[:20]:\n",
    "            print(i[0], i[1])\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f'{influencer}: {word_dict[\"cancel\"]}')\n",
    "            print(f'{influencer}: {word_dict[\"boycott\"]}')\n",
    "        except KeyError:\n",
    "            print(f'{influencer}: No \"cancel\" or \"boycott\" found')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for influencer in unique_influencers:\n",
    "    try:\n",
    "        infl_info = api.get_user(influencer)\n",
    "        print(f'{influencer}: {infl_info.description}')\n",
    "    except:\n",
    "        print(f'Was {influencer} suspended?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take each \"influencer\" and \n",
    "# 1. get their verified percentage\n",
    "# 2. get the veerified percentage of *their* followers\n",
    "# This code block is doable, but will take an unrealistic amount of time.\n",
    "# It is best to skip this for now until a better algorith, shjows itself....or better metric\n",
    "for influencer in influencers:\n",
    "    verified = []\n",
    "    unverified = []\n",
    "    influencer_followers = api.followers_ids(influencer)\n",
    "    for account in influencer_followers:\n",
    "        acc_info = api.get_user(account)\n",
    "        if acc_info.verified == True:\n",
    "            verified.append(account)\n",
    "        else:\n",
    "            unverified.append(account)\n",
    "        time.sleep(15)\n",
    "    print(len(verified))\n",
    "    print(len(unverified))\n",
    "    verify_percent = len(verified)/len(influencer_followers)\n",
    "    print(f'{influencer}: {verify_percent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple analysis of a user's bio/desription\n",
    "with open(\"follower_bios.txt\", \"w+\") as f_file:\n",
    "    for follower in followers:\n",
    "        account = api.get_user(follower)\n",
    "        desc_string = f'{account.screen_name}: {account.description}'\n",
    "        print(desc_string)\n",
    "        f_file.write(desc_string)\n",
    "        f_file.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis on the followers that were considered to be \"influencers\"\n",
    "for influencer in unique_influencers:\n",
    "    sentiments = []\n",
    "    with open(f'{influencer}.txt', 'r') as test_file:\n",
    "        tweets = test_file.readlines()\n",
    "        for tweet in tweets:\n",
    "            tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "            sent_analysis = TextBlob(tweet)\n",
    "            if sent_analysis.sentiment.polarity > 0:\n",
    "                sentiments.append('positive')\n",
    "            elif sent_analysis.sentiment.polarity == 0:\n",
    "                sentiments.append('neutral')\n",
    "            else:\n",
    "                sentiments.append('negative')\n",
    "        print(f'---{influencer}---')\n",
    "        try:\n",
    "            print(f'Positive Sentiment Percentage: {sentiments.count(\"positive\")/len(sentiments)}')\n",
    "            print(f'Negative Sentiment Percentage: {sentiments.count(\"negative\")/len(sentiments)}')\n",
    "            print(f'Neutral Sentiment Percentage: {sentiments.count(\"neutral\")/len(sentiments)}')\n",
    "        except:\n",
    "            print(\"Potential singularity here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-ranch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
